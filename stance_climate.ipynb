{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (C:/Users/User/.cache/huggingface/datasets/tweet_eval/stance_climate/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d25b15150e647a5b83149608492bda5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tweet_eval\", \"stance_climate\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 355\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 40\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['text', 'label'],\n    num_rows: 40\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\User\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-22c2d61fa626c275.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/169 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a90cc78ef8b24ff39fe0c5b0b34c72af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\User\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-c468eff055c85d56.arrow\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Get the input_ids from the tokenized dataset for train, validation, and test sets\n",
    "train_input_ids = [example['input_ids'] for example in tokenized_dataset['train']]\n",
    "val_input_ids = [example['input_ids'] for example in tokenized_dataset['validation']]\n",
    "test_input_ids = [example['input_ids'] for example in tokenized_dataset['test']]\n",
    "\n",
    "# Convert input_ids to PyTorch tensors\n",
    "train_input_ids = torch.tensor(train_input_ids, dtype=torch.long)\n",
    "val_input_ids = torch.tensor(val_input_ids, dtype=torch.long)\n",
    "test_input_ids = torch.tensor(test_input_ids, dtype=torch.long)\n",
    "\n",
    "# Concatenate the input_ids tensors along the first dimension\n",
    "input_ids = torch.cat((train_input_ids, val_input_ids, test_input_ids), dim=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\User\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-b86cb2279c9c7cb0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\User\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-87fcbc7a7e61f00f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\User\\.cache\\huggingface\\datasets\\tweet_eval\\stance_climate\\1.1.0\\12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343\\cache-c468eff055c85d56.arrow\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Get the attention_masks from the tokenized dataset for train, validation, and test sets\n",
    "train_attention_mask = [example['attention_mask'] for example in tokenized_dataset['train']]\n",
    "val_attention_mask = [example['attention_mask'] for example in tokenized_dataset['validation']]\n",
    "test_attention_mask = [example['attention_mask'] for example in tokenized_dataset['test']]\n",
    "\n",
    "# Convert attention_mask to PyTorch tensors\n",
    "train_attention_mask = torch.tensor(train_attention_mask, dtype=torch.long)\n",
    "val_attention_mask = torch.tensor(val_attention_mask, dtype=torch.long)\n",
    "test_attention_mask = torch.tensor(test_attention_mask, dtype=torch.long)\n",
    "\n",
    "# Concatenate the input_ids tensors along the first dimension\n",
    "attention_masks = torch.cat((train_attention_mask, val_attention_mask, test_attention_mask), dim=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,  483,   25,  ...,    0,    0,    0],\n",
      "        [   2,   95,  555,  ...,    0,    0,    0],\n",
      "        [   2,   32,   22,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,  100,   95,  ...,    0,    0,    0],\n",
      "        [   2, 1511,  414,  ...,    0,    0,    0],\n",
      "        [   2,   32,   22,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(attention_masks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "val_dataset = tokenized_dataset[\"validation\"]\n",
    "test_dataset = tokenized_dataset[\"test\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Convert the datasets to PyTorch tensors\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class StanceClimateModel(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(StanceClimateModel, self).__init__()\n",
    "        self.albert = AlbertModel.from_pretrained('albert-base-v2')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.albert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.albert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# instantiate your model\n",
    "stance_climate_model = StanceClimateModel(num_classes=3).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# define your loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# define your optimizer\n",
    "optimizer = torch.optim.Adam(stance_climate_model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# set up your training, validation, and test dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': tensor([0, 1, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 2]), 'input_ids': tensor([[   2,  750,   25,  ...,    0,    0,    0],\n",
      "        [   2,  636,  177,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   95,  376,  ...,    0,    0,    0],\n",
      "        [   2, 9227, 1953,  ...,    0,    0,    0],\n",
      "        [   2, 7677,  279,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2]), 'input_ids': tensor([[   2,   86, 6926,  ...,    0,    0,    0],\n",
      "        [   2, 3414,   28,  ...,    0,    0,    0],\n",
      "        [   2, 9644,   30,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 1679,   17,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0]), 'input_ids': tensor([[   2,  483,   25,  ...,    0,    0,    0],\n",
      "        [   2,   14, 1112,  ...,    0,    0,    0],\n",
      "        [   2, 6926,  103,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 2346,   88,  ...,    0,    0,    0],\n",
      "        [   2,   32,   22,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 1, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0]), 'input_ids': tensor([[   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 3045,  753,  ...,    0,    0,    0],\n",
      "        [   2,   64, 3834,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 5371,   41,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 6926,  444,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0]), 'input_ids': tensor([[   2, 1131,   20,  ...,    0,    0,    0],\n",
      "        [   2,  415,  596,  ...,    0,    0,    0],\n",
      "        [   2,   28,   59,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 2448,  941,  ...,    0,    0,    0],\n",
      "        [   2, 4818,   15,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0]), 'input_ids': tensor([[    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    31,    92,  ...,     0,     0,     0],\n",
      "        [    2,   100,   101,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,   353, 18854,  ...,     0,     0,     0],\n",
      "        [    2,   331,     8,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 1, 2, 0]), 'input_ids': tensor([[    2,  2251,    13,  ...,     0,     0,     0],\n",
      "        [    2,  4483,  6926,  ...,     0,     0,     0],\n",
      "        [    2,   566,    13,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  1525,    13,  ...,     0,     0,     0],\n",
      "        [    2,  6926, 12385,  ...,     0,     0,     0],\n",
      "        [    2,  6926, 25102,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2]), 'input_ids': tensor([[    2,   406, 13524,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,   483,    25,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  1249,   101,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    35,   172,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 0, 0, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0]), 'input_ids': tensor([[    2,   374,    20,  ...,     0,     0,     0],\n",
      "        [    2,   374,  1235,  ...,     0,     0,     0],\n",
      "        [    2,   152, 20813,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    35,  1316,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2]), 'input_ids': tensor([[   2,   14, 5716,  ...,    0,    0,    0],\n",
      "        [   2, 9981, 2881,  ...,    0,    0,    0],\n",
      "        [   2, 3892,   45,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,  308, 3348,  ...,    0,    0,    0],\n",
      "        [   2, 6926, 5582,  ...,    0,    0,    0],\n",
      "        [   2,   98,   25,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2]), 'input_ids': tensor([[    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,  1938,    68,  ...,     0,     0,     0],\n",
      "        [    2, 21706,    68,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    13,     9,  ...,     0,     0,     0],\n",
      "        [    2,  1876,    45,  ...,     0,     0,     0],\n",
      "        [    2,    13,    22,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0]), 'input_ids': tensor([[    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,  3521, 11255,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,   114,  1302,  ...,     0,     0,     0],\n",
      "        [    2, 15849,  7677,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2]), 'input_ids': tensor([[   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 2726, 2622,  ...,    0,    0,    0],\n",
      "        [   2, 6926,   18,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2,  402,   18,  ...,    0,    0,    0],\n",
      "        [   2,   57,  243,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2, 0, 2, 2, 2]), 'input_ids': tensor([[   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2, 3441,   18,  ...,    0,    0,    0],\n",
      "        [   2, 6926, 9734,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2, 6926, 6232,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2,   80,   25,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2]), 'input_ids': tensor([[    2,  3727,   100,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    13,     9,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,   100,    95,  ...,     0,     0,     0],\n",
      "        [    2,   162,  2117,  ...,     0,     0,     0],\n",
      "        [    2, 14179, 18035,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 0, 2, 2, 2, 2, 2, 0, 2, 1, 0, 0, 0, 0, 2, 0]), 'input_ids': tensor([[    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    32,    22,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 10314,  1397,  ...,     0,     0,     0],\n",
      "        [    2,    14,  6926,  ...,     0,     0,     0],\n",
      "        [    2,    13, 15530,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 1, 2, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 0, 0]), 'input_ids': tensor([[    2,    14, 12838,  ...,     0,     0,     0],\n",
      "        [    2,  2062, 15075,  ...,     0,     0,     0],\n",
      "        [    2,   100,    42,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    76,   154,  ...,     0,     0,     0],\n",
      "        [    2,    13,     9,  ...,     0,     0,     0],\n",
      "        [    2,   483,    25,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0]), 'input_ids': tensor([[   2, 1191, 1430,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        [   2,   13,    1,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,  153, 1737,  ...,    0,    0,    0],\n",
      "        [   2,   21, 2117,  ...,    0,    0,    0],\n",
      "        [   2, 5289, 2421,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 1, 2]), 'input_ids': tensor([[    2,  2593,    38,  ...,     0,     0,     0],\n",
      "        [    2,   750,     9,  ...,     0,     0,     0],\n",
      "        [    2,    28,    14,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  6926, 12385,  ...,     0,     0,     0],\n",
      "        [    2,   100,    14,  ...,     0,     0,     0],\n",
      "        [    2,  6926, 18379,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1]), 'input_ids': tensor([[    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,   998,    15,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  5320,    21,  ...,     0,     0,     0],\n",
      "        [    2,  2060, 10727,  ...,     0,     0,     0],\n",
      "        [    2,    13,  8430,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2]), 'input_ids': tensor([[    2,    95,    50,  ...,     0,     0,     0],\n",
      "        [    2,  6926,  6232,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  6926,  4386,  ...,     0,     0,     0],\n",
      "        [    2,    13,     1,  ...,     0,     0,     0],\n",
      "        [    2,  6926, 12385,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0]), 'input_ids': tensor([[  2,  13,   1,  ...,   0,   0,   0],\n",
      "        [  2, 366,  21,  ...,   0,   0,   0],\n",
      "        [  2, 100, 598,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  2,  32,  22,  ...,   0,   0,   0],\n",
      "        [  2,  13,   9,  ...,   0,   0,   0],\n",
      "        [  2,  13,   9,  ...,   0,   0,   0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'label': tensor([2, 2, 2]), 'input_ids': tensor([[    2,   239, 13795,  9050,    25,  6237,    13, 19128,   150,  1235,\n",
      "            20,   448,  2539,    14,  1022,    16,   294, 17329,  1692, 18609,\n",
      "         25390,  3195,  6926,    18,  1503,   384,     3,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,    31,   221,    22,    38,   259,    20,    44,    13,     7,\n",
      "           887,  1244,     7,    47,    92,    95,   130,   233,    13,     7,\n",
      "         24487,    62,   753,   121,  9070,  1722,     7,  5143,    60,  6926,\n",
      "         23768, 23011, 20901,  6926,  3448,    58,  6926,    18,  1503,   384,\n",
      "             3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,   598,   662,  2529,    34,    14,   241,    16,    14,   428,\n",
      "            13,     5,   165,     8,   135,  4322,     6,   129, 20380, 15025,\n",
      "          1282,    17,   333,  1295,     9,    13,     1, 16704,  6926,  1410,\n",
      "         18415,    18,  5991,  6926,    18,  1503,   384,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   4%|▍         | 1/23 [00:32<11:55, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.056, Train Acc: 0.000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   9%|▊         | 2/23 [01:03<11:02, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.092, Train Acc: 0.250\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  13%|█▎        | 3/23 [01:46<12:12, 36.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.190, Train Acc: 0.250\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  17%|█▋        | 4/23 [02:21<11:29, 36.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.450, Train Acc: 0.312\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  22%|██▏       | 5/23 [02:57<10:48, 36.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.559, Train Acc: 0.338\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  26%|██▌       | 6/23 [03:32<10:07, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.661, Train Acc: 0.333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  30%|███       | 7/23 [04:08<09:33, 35.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.729, Train Acc: 0.357\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  35%|███▍      | 8/23 [04:44<08:57, 35.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.803, Train Acc: 0.391\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  39%|███▉      | 9/23 [05:21<08:25, 36.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.052, Train Acc: 0.347\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  43%|████▎     | 10/23 [05:56<07:47, 35.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.101, Train Acc: 0.381\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  48%|████▊     | 11/23 [06:32<07:10, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.187, Train Acc: 0.386\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  52%|█████▏    | 12/23 [07:07<06:33, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.256, Train Acc: 0.391\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  57%|█████▋    | 13/23 [07:42<05:54, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.320, Train Acc: 0.413\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  61%|██████    | 14/23 [08:07<04:50, 32.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.356, Train Acc: 0.433\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  65%|██████▌   | 15/23 [08:32<04:00, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.414, Train Acc: 0.417\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  70%|██████▉   | 16/23 [08:57<03:19, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.449, Train Acc: 0.430\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  74%|███████▍  | 17/23 [09:22<02:45, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.496, Train Acc: 0.434\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  78%|███████▊  | 18/23 [09:47<02:14, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.527, Train Acc: 0.438\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  83%|████████▎ | 19/23 [10:13<01:45, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.556, Train Acc: 0.447\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  87%|████████▋ | 20/23 [10:38<01:17, 25.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.598, Train Acc: 0.447\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  91%|█████████▏| 21/23 [11:03<00:51, 25.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.655, Train Acc: 0.446\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  96%|█████████▌| 22/23 [11:28<00:25, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.698, Train Acc: 0.440\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 23/23 [11:33<00:00, 30.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.728, Train Acc: 0.442\n",
      "Epoch 1 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # get the inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = stance_climate_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # print running loss for each batch\n",
    "        running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        avg_acc = correct_predictions / total_predictions\n",
    "        tqdm.write(f'Train Loss: {avg_loss:.3f}, Train Acc: {avg_acc:.3f}', end='\\r')\n",
    "    tqdm.write(f'Epoch {epoch+1}, Train Loss: {avg_loss:.3f}, Train Acc: {avg_acc:.3f}')\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.287, Validation Acc: 0.525\n"
     ]
    }
   ],
   "source": [
    "# Validation loop\n",
    "with torch.no_grad():\n",
    "    stance_climate_model.eval()  # Set the model to evaluation mode\n",
    "    valid_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for batch in val_loader:\n",
    "        # get the inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = stance_climate_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # calculate running loss\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    avg_loss = valid_loss / len(val_loader)\n",
    "    avg_acc = correct_predictions / total_predictions\n",
    "    print(f'Validation Loss: {avg_loss:.3f}, Validation Acc: {avg_acc:.3f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.219, Test Acc: 0.728\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test loop\n",
    "with torch.no_grad():\n",
    "    stance_climate_model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for batch in test_loader:\n",
    "        # get the inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = stance_climate_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # calculate running loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    avg_acc = correct_predictions / total_predictions\n",
    "    print(f'Test Loss: {avg_loss:.3f}, Test Acc: {avg_acc:.3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(stance_climate_model.state_dict(), 'Models/stance_climate_model.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
